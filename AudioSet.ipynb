{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preliminary cell to start the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "DTfr58OTHE68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.11.4 (main, Jul  5 2023, 08:54:11) [Clang 14.0.6 ]\n",
            "TensorFlow version: 2.12.0\n",
            "keras version = 2.12.0\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "print(sys.version)\n",
        "\n",
        "strong_pc = platform.system() == 'Linux'\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "if in_colab:\n",
        "    if not os.getcwd().split('/')[-1].split('_')[-1]=='2023':\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        os.chdir(r'/content/drive/MyDrive/Human_Data_Analytics_Project_2023')\n",
        "\n",
        "    #!pip install tensorflow==2.11.0\n",
        "    #!pip install tensorflow_text==2.11.0\n",
        "    if not 'tensorflow_io' in sys.modules:\n",
        "        print('Installing tensorflow-IO')\n",
        "        !pip install tensorflow-io\n",
        "    if not 'keras' in sys.modules and False:\n",
        "        print('Installing keras')\n",
        "        !pip install keras==2.11.0\n",
        "    if not 'scikeras' in sys.modules:\n",
        "        print('Installing scikeras')\n",
        "        !pip install scikeras[tensorflow]\n",
        "    if not 'keras-tuner' in sys.modules:\n",
        "        print('installing keras tuner')\n",
        "        !pip install keras-tuner\n",
        "        !pip install numba==0.57.0\n",
        "\n",
        "\n",
        "if 'DEEPNOTE_ENV' in os.environ:\n",
        "    os.chdir('/..')\n",
        "    os.chdir('datasets')\n",
        "    os.chdir('googledrivedeepnoteintegration')\n",
        "    os.chdir('Human_Data_Analytics_Project_2023')\n",
        "    if not 'librosa' in sys.modules:\n",
        "        print('Installing Librosa')\n",
        "        !pip install librosa\n",
        "    if not 'scikeras' in sys.modules:\n",
        "        print('Installing scikeras')\n",
        "        !pip install scikeras[tensorflow]\n",
        "    if not 'keras-tuner' in sys.modules:\n",
        "        print('installing keras tuner')\n",
        "        !pip install keras-tuner\n",
        "        !pip install numba==0.57.0\n",
        "\n",
        "main_dir = os.getcwd()\n",
        "if main_dir not in sys.path:\n",
        "    print('Adding the folder for the modules')\n",
        "    sys.path.append(main_dir)\n",
        "\n",
        "#BASE LIBRARIES\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import subprocess\n",
        "import itertools\n",
        "import warnings\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "#PLOT LIBRARIES\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import IPython.display as ipd\n",
        "#import plotly.express as px\n",
        "\n",
        "#AUDIO LIBRARIES\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal\n",
        "from scipy.fft import fft,ifft,fftfreq, fftshift\n",
        "from scipy.signal import stft,spectrogram,periodogram\n",
        "#from pydub import AudioSegment\n",
        "\n",
        "#MACHINE LEARNING LIBRARIES\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.utils import check_random_state\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# GPU SETTINGS FOR LINUX and repressing warnings for windows. References for gpu: https://www.tensorflow.org/guide/gpu\n",
        "show_gpu_activity = False\n",
        "if sys.platform == 'linux' and not in_colab:\n",
        "    if show_gpu_activity:\n",
        "        tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "    # Restrict TensorFlow to only allocate a part of memory on the first GPU\n",
        "        try:\n",
        "            tf.config.set_logical_device_configuration(\n",
        "                gpus[0],\n",
        "                [tf.config.LogicalDeviceConfiguration(memory_limit=6800)])\n",
        "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "        except RuntimeError as e:\n",
        "            # Virtual devices must be set before GPUs have been initialized\n",
        "            print(e)\n",
        "else:\n",
        "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.utils import plot_model as tf_plot\n",
        "if in_colab:\n",
        "    import tensorflow_io as tfio\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "# show keras version\n",
        "import keras\n",
        "print(f'keras version = {keras.__version__}')\n",
        "#import keras_tune as kt\n",
        "from keras import layers\n",
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "# kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4) # we may use this in some layers...\n",
        "\n",
        "#RANDOM SETTINGS\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "check_random_state(seed)\n",
        "\n",
        "#EVALUATION LIBRAIRES\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import RocCurveDisplay, precision_recall_curve, PrecisionRecallDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support, auc\n",
        "\n",
        "#OUR PERSONAL FUNCTIONS\n",
        "import importlib\n",
        "from Preprocessing.data_loader import download_dataset,load_metadata\n",
        "from Preprocessing.exploration_plots import one_random_audio, plot_clip_overview, Spectral_Analysis\n",
        "from Models.basic_ml import basic_ML_experiments, basic_ML_experiments_gridsearch, build_dataset, extract_flatten_MFCC\n",
        "from Visualization.model_plot import confusion_matrix,listen_to_wrong_audio\n",
        "\n",
        "importlib.reload(importlib.import_module('Preprocessing.data_loader'))\n",
        "importlib.reload(importlib.import_module('Models.basic_ml'))\n",
        "importlib.reload(importlib.import_module('Visualization.model_plot'))\n",
        "\n",
        "from Preprocessing.data_loader import load_metadata\n",
        "df_ESC10, df_ESC50 = load_metadata(main_dir,heads = False, ESC_US = False, statistics=False)\n",
        "\n",
        "from Preprocessing.data_loader import load_metadata\n",
        "from Models.basic_ml import basic_ML_experiments, basic_ML_experiments_gridsearch, build_dataset, extract_flatten_MFCC\n",
        "\n",
        "importlib.reload(importlib.import_module('Models.ann_utils'))\n",
        "importlib.reload(importlib.import_module('Visualization.model_plot'))\n",
        "\n",
        "from Models.ann_utils import *\n",
        "from Models.ann_utils import MFCCWithDeltaLayer,OutputCutterLayer\n",
        "from Visualization.model_plot import plot_history, confusion_matrix, listen_to_wrong_audio, visualize_the_weights\n",
        "\n",
        "ESC10_path = os.path.join(main_dir,'Data', 'ESC-10-depth')\n",
        "samplerate = 22500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "hdbavU21HH2U"
      },
      "outputs": [],
      "source": [
        "main_dir = os.getcwd()\n",
        "subfolder_path = os.path.join(main_dir, 'Data','balanced')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to delete all the files which are too short or too long, we keep 10 sec files and we will sample half times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyKb76jUWsVz",
        "outputId": "def6a0f3-6e06-42c8-e375-dcd566485b7c"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Function to check audio duration\n",
        "def check_audio_duration(audio_path, target_duration):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        duration_seconds = len(audio) / 1000  # Convert milliseconds to seconds\n",
        "        return duration_seconds == target_duration  # Check if duration is exactly equal to the target duration\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "\n",
        "# Set the root folder path\n",
        "root_folder = os.path.join(main_dir, 'Data', 'AudioSet')\n",
        "\n",
        "# Target duration in seconds    \n",
        "target_duration = 10\n",
        "file_count = 0\n",
        "remode_file = 0\n",
        "\n",
        "# Iterate through all files in the directory and its subdirectories\n",
        "for root, dirs, files in os.walk(root_folder):\n",
        "    for file in files:\n",
        "        # Check if the file has an audio file extension (e.g., .mp3, .wav, .ogg, etc.)\n",
        "        if file.endswith(('.mp3', '.wav', '.ogg', '.flac', '.aac')):\n",
        "            audio_path = os.path.join(root, file)\n",
        "            file_count += 1\n",
        "            if not check_audio_duration(audio_path, target_duration):\n",
        "                # delete the file\n",
        "                os.remove(audio_path)\n",
        "                remode_file += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files: 49625\n",
            "Number of removed files: 2885\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of files: {file_count}')\n",
        "print(f'Number of removed files: {remode_file}') # around 3000 files removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Renaming the folders from name = label, to name = number in order to use US_training (modified into AS_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#renaming the folders\n",
        "\n",
        "import os\n",
        "# Set the root folder path\n",
        "path = os.path.join(main_dir, 'Data', 'AudioSet')\n",
        "count = 1\n",
        "for folder_name in sorted(os.listdir(path)):\n",
        "    if os.path.isdir(os.path.join(path, folder_name)):\n",
        "        # Create a new name with a three-digit number\n",
        "        new_name = f\"{count:03d}\"\n",
        "        \n",
        "        # Construct the full paths to the old and new folders\n",
        "        old_folder_path = os.path.join(path, folder_name)\n",
        "        new_folder_path = os.path.join(path, new_name)\n",
        "        \n",
        "        # Rename the subfolder\n",
        "        os.rename(old_folder_path, new_folder_path)\n",
        "        \n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting wav files if needed (skipped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If we want to convert the audio files to OGG format, we can use the following code:\n",
        "# But we do not do it because it takes too long, instead we use the original files modifying the function create_dataset\n",
        "\n",
        "# Set the root folder path\n",
        "root_folder = os.path.join(main_dir, 'Data', 'AudioSet')\n",
        "\n",
        "# Iterate through all files in the directory and its subdirectories\n",
        "for root, dirs, files in os.walk(root_folder):\n",
        "    for file in files:\n",
        "        # Check if the file has a WAV file extension\n",
        "        if file.endswith('.wav'):\n",
        "            # Construct the full path to the file\n",
        "            file_path = os.path.join(root, file)\n",
        "            \n",
        "            # Specify the output OGG file path\n",
        "            ogg_file_path = file_path.replace('.wav', '.ogg')\n",
        "            \n",
        "            # Use VLC to convert WAV to OGG format with a timeout of 60 seconds\n",
        "            vlc_command = [\n",
        "                '/Applications/VLC.app/Contents/MacOS/VLC',\n",
        "                '--intf', 'dummy',  # Use the dummy interface (no GUI)\n",
        "                '--no-sout-video',  # Disable video output\n",
        "                '--sout', f'#transcode{{acodec=vorb,ab=128,channels=2,samplerate=44100}}:std{{access=file,mux=ogg,dst=\"{ogg_file_path}\"}}',\n",
        "                file_path  # Input WAV file\n",
        "            ]\n",
        "            \n",
        "            # Run the VLC command with a timeout\n",
        "            try: \n",
        "                completed_process = subprocess.run(vlc_command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=0.5)\n",
        "            except subprocess.TimeoutExpired:\n",
        "                #check if there exists a file with the same name and its weight is not 0\n",
        "                if os.path.exists(ogg_file_path) and os.path.getsize(ogg_file_path) > 0:\n",
        "                    #print(f'Converted \"{file_path}\" to \"{ogg_file_path}\"')\n",
        "                    continue\n",
        "                else:\n",
        "                    try:\n",
        "                        completed_process = subprocess.run(vlc_command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=1)\n",
        "                    except subprocess.TimeoutExpired:\n",
        "                        if os.path.exists(ogg_file_path) and os.path.getsize(ogg_file_path) > 0:\n",
        "                            #print(f'Converted \"{file_path}\" to \"{ogg_file_path}\"')\n",
        "                            continue\n",
        "                        else: \n",
        "                            try:\n",
        "                                completed_process = subprocess.run(vlc_command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=10)\n",
        "                            except subprocess.TimeoutExpired:\n",
        "                                if os.path.exists(ogg_file_path) and os.path.getsize(ogg_file_path) > 0:\n",
        "                                    #print(f'Converted \"{file_path}\" to \"{ogg_file_path}\"')\n",
        "                                    continue\n",
        "                                else:\n",
        "                                    print(f'Failed to convert \"{file_path}\" to \"{ogg_file_path}\"')\n",
        "                                    continue\n",
        "                    continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autoencoder training (using 3.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocessing = 'STFT'\n",
        "AE_name = 'AE_Conv_prep_flatten_'+preprocessing + '_AudioSet'\n",
        "train, val, test, INPUT_DIM = create_AS_dataset('001')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created AE_Conv_prep_flatten_STFT_AudioSet_count.txt with content '0' in folder Saved_Models\n"
          ]
        }
      ],
      "source": [
        "folder_path = 'Saved_Models'  # Replace this with the actual folder path\n",
        "file_names = [ AE_name+'_count.txt']\n",
        "\n",
        "for name in file_names:\n",
        "    file_path = os.path.join(main_dir, folder_path, name)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write('0')\n",
        "    print(f\"Created {name} with content '0' in folder {folder_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "#General function to build an autoencoder\n",
        "#CONVOLUTIONAL AUTOENCODER WITH VECTORIAL CODE\n",
        "code_size = 32\n",
        "n_layers = 2\n",
        "n_units = 32\n",
        "\n",
        "# the real build function for general autoencoder (keras code)\n",
        "def build_autoencoder(img_shape = INPUT_DIM,\n",
        "                      code_size = code_size,\n",
        "                      activation = 'tanh',\n",
        "                      padding = 'valid',\n",
        "                      n_layers = n_layers, #max number of layers is 3\n",
        "                      n_units = n_units,\n",
        "                      kernel_size = (3,3),\n",
        "                      strides = (2,2),\n",
        "                      max_pooling = (2,2),\n",
        "                      regularizer = 1e-4,\n",
        "                      batch_norm = True,\n",
        "                      drop_out = 0.0,\n",
        "                      learning_rate = 1e-3,\n",
        "                      loss = tf.keras.losses.MeanSquaredError(),\n",
        "                      metrics = ['mse'],\n",
        "                      AE_name = AE_name\n",
        " ):\n",
        "    lr = learning_rate\n",
        "    # encoder\n",
        "    encoder = tf.keras.Sequential(name='Encoder')\n",
        "    encoder.add(tf.keras.Input(img_shape))\n",
        "    for i in range(n_layers):\n",
        "        encoder.add(layers.Conv2D(n_units * (i+1), kernel_size,strides = strides, activation = activation, padding=padding))\n",
        "        encoder.add(layers.MaxPool2D(max_pooling, padding='same'))\n",
        "        if batch_norm:\n",
        "            encoder.add(layers.BatchNormalization())\n",
        "        if drop_out > 0:\n",
        "            encoder.add(layers.Dropout(drop_out))\n",
        "\n",
        "    # flatten layer to get the code\n",
        "    my_shape = encoder.layers[-1].output_shape\n",
        "    encoder.add(layers.Flatten())\n",
        "    encoder.add(layers.Dense(code_size,activation = activation, activity_regularizer=keras.regularizers.l1(regularizer)))\n",
        "\n",
        "    # decoder\n",
        "    decoder = tf.keras.Sequential(name='Decoder')\n",
        "    decoder.add(tf.keras.Input(code_size))\n",
        "    decoder.add(layers.Dense(np.prod(my_shape[1:]), activation=activation))\n",
        "    decoder.add(layers.Reshape(my_shape[1:]))\n",
        "\n",
        "    # transpose convolutions\n",
        "    for i in range(n_layers):\n",
        "        filters = n_units * (n_layers-i) if i<n_layers-1 else 1\n",
        "        decoder.add(layers.Conv2DTranspose(filters , kernel_size, strides=strides, activation=activation, padding=padding))\n",
        "        decoder.add(layers.UpSampling2D(size=max_pooling))\n",
        "        if batch_norm:\n",
        "            decoder.add(layers.BatchNormalization())\n",
        "\n",
        "    #final reshape\n",
        "    decoder.add(tf.keras.layers.Resizing(height = INPUT_DIM[0], width = INPUT_DIM[1], interpolation=\"bilinear\", crop_to_aspect_ratio=False))\n",
        "\n",
        "    # build the autoencoder with keras.Model\n",
        "    inp = tf.keras.Input(shape = INPUT_DIM)\n",
        "    code = encoder(inp)\n",
        "    reconstruction = decoder(code)\n",
        "    autoencoder = tf.keras.Model(inputs=inp, outputs=reconstruction, name = AE_name)\n",
        "\n",
        "    # compile the autoencoder\n",
        "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr) if sys.platform == 'darwin' or in_colab else tf.keras.optimizers.Adam(learning_rate = lr)\n",
        "    loss = loss\n",
        "    metrics = metrics\n",
        "\n",
        "    autoencoder.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=metrics)\n",
        "\n",
        "    #print the number of trainable parameters\n",
        "    print(f'Model built with { sum(tf.keras.backend.count_params(p) for p in autoencoder.trainable_variables)} trainable params')\n",
        "\n",
        "    return autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now, you have a TensorFlow dataset with spectrograms and labels.\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from scipy.interpolate import RegularGridInterpolator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_AS_dataset(folder,val_split = 0.25): #folder = '001'\n",
        "    # Create an empty list to store spectrograms and labels\n",
        "    spectrograms = []\n",
        "\n",
        "    # Define the target shape for spectrograms\n",
        "    target_shape = (64, 128)\n",
        "\n",
        "    list_audio_files = os.listdir(os.path.join(main_dir, 'Data', 'AudioSet', folder))\n",
        "\n",
        "    for audio_file in list_audio_files:\n",
        "        audio_path = os.path.join(main_dir, 'Data', 'AudioSet', folder , audio_file)\n",
        "        audio, sr = librosa.load(audio_path, sr=22050, mono=True)\n",
        "        stft = librosa.stft(audio)\n",
        "\n",
        "        # Create a grid of indices for the original spectrogram\n",
        "        x = np.linspace(0, stft.shape[1] - 1, stft.shape[1])\n",
        "        y = np.linspace(0, stft.shape[0] - 1, stft.shape[0])\n",
        "\n",
        "        # Create the interpolator function\n",
        "        interpolator = RegularGridInterpolator((y, x), stft)\n",
        "\n",
        "        # Create a grid of indices for the target shape\n",
        "        target_x = np.linspace(0, stft.shape[1] - 1, target_shape[1])\n",
        "        target_y = np.linspace(0, stft.shape[0] - 1, target_shape[0])\n",
        "\n",
        "        # Create a meshgrid of target indices\n",
        "        target_x, target_y = np.meshgrid(target_x, target_y)\n",
        "\n",
        "        # Stack the indices as a 2D array\n",
        "        target_indices = np.vstack((target_y.ravel(), target_x.ravel())).T\n",
        "\n",
        "        # Interpolate to get the resized STFT\n",
        "        stft = interpolator(target_indices).reshape(target_shape)\n",
        "\n",
        "        # Change dim to (64, 128, 1)\n",
        "        stft = stft.reshape(64, 128, 1)\n",
        "\n",
        "        # Append the spectrogram and label to the lists (modify this part to include labels)\n",
        "        spectrograms.append(stft)\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    spectrograms = np.array(spectrograms)\n",
        "\n",
        "    # Create a TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((spectrograms))\n",
        "\n",
        "    # Shuffle and batch the dataset (modify batch size and buffer size as needed)\n",
        "    batch_size = 32\n",
        "    buffer_size = 1000\n",
        "\n",
        "    #divide into train, val, test\n",
        "    dataset = dataset.shuffle(buffer_size)\n",
        "    n = len(dataset)\n",
        "    n_val = int(n*val_split)\n",
        "    n_test = int(n*val_split)\n",
        "    n_train = n - n_val - n_test\n",
        "    train = dataset.take(n_train)\n",
        "    val = dataset.skip(n_train).take(n_val)\n",
        "    test = dataset.skip(n_train+n_val).take(n_test)\n",
        "    \n",
        "    #batch the dataset\n",
        "    train = train.batch(batch_size)\n",
        "    val = val.batch(batch_size)\n",
        "    test = test.batch(batch_size)\n",
        "\n",
        "    INPUT_DIM = spectrograms[0].shape\n",
        "\n",
        "    return train, val, test, INPUT_DIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "def AS_training(AE_name,\n",
        "                autoencoder,\n",
        "                n_folders,\n",
        "                epochs = 50,\n",
        "                preprocessing = None,\n",
        "                patience=10,\n",
        "                verbose = 0,\n",
        "                ndim = 3,\n",
        "                metrics = ['mse'],\n",
        "                ):\n",
        "\n",
        "    #paramteres for the fit and callbacks\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_'+metrics[0],\n",
        "                                                mode='max',\n",
        "                                                verbose=verbose,\n",
        "                                                restore_best_weights=True,\n",
        "                                                patience=patience)]\n",
        "\n",
        "    #read the file txt to know the folder to start \n",
        "    with open(os.path.join(main_dir,'Saved_Models',AE_name+'_count.txt'), 'r') as file:\n",
        "        last_folder = int(file.read())\n",
        "        print(f'Last folder trained: {last_folder}')\n",
        "\n",
        "    if n_folders < last_folder:\n",
        "        print('The number of folders is smaller than the last folder trained!')\n",
        "        n_folders = last_folder\n",
        "    \n",
        "    for i in range(last_folder+1,n_folders+1):\n",
        "\n",
        "        #load the model if i > 1\n",
        "        if i>1:\n",
        "            autoencoder = tf.keras.models.load_model(os.path.join(main_dir,'Saved_Models',AE_name))\n",
        "\n",
        "        #create the dataset\n",
        "        train, val, test, INPUT_DIM =  create_AS_dataset(folder_number=i,\n",
        "                                                        preprocessing = preprocessing,\n",
        "                                                        ndim = ndim,\n",
        "                                                        main_dir = main_dir,\n",
        "                                                        )\n",
        "        \n",
        "        #fit the autoencoder\n",
        "        history = autoencoder.fit(train, validation_data= val, epochs=epochs, callbacks = callbacks, verbose=0)\n",
        "\n",
        "        #save the model\n",
        "        autoencoder.save(os.path.join(main_dir,'Saved_Models',AE_name), save_format  ='keras')\n",
        "\n",
        "        #show the best epoch\n",
        "        val_acc_per_epoch = history.history['val_'+metrics[0]]\n",
        "        best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "        if verbose > 0:\n",
        "            print('Best epoch: %d' % (best_epoch,))\n",
        "        \n",
        "        if verbose > 1:\n",
        "            #plot the history of the training\n",
        "            plot_history(history)\n",
        "\n",
        "            #evaluate the model on the test set\n",
        "            scores = autoencoder.evaluate(test, return_dict=False)\n",
        "            display(scores)\n",
        "\n",
        "        #update the number on the txt file overwritting the previoAS one\n",
        "        with open(os.path.join(main_dir,'Saved_Models',AE_name+'_count.txt'), 'w') as file:\n",
        "            file.write(str(i))\n",
        "\n",
        "    # retrive the size of the model\n",
        "    print(f\"This model has a size of {get_model_size(autoencoder)} MB\")\n",
        "     \n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model built with 102257 trainable params\n",
            "Model: \"AE_Conv_prep_flatten_STFT_AudioSet\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 64, 128, 1)]      0         \n",
            "                                                                 \n",
            " Encoder (Sequential)        (None, 32)                50368     \n",
            "                                                                 \n",
            " Decoder (Sequential)        (None, 64, 128, 1)        51889     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,257\n",
            "Trainable params: 102,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Last folder trained: 0\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "create_AS_dataset() got an unexpected keyword argument 'folder_number'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb Cella 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m n_folders \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m#528\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m AS_training(AE_name \u001b[39m=\u001b[39m AE_name, autoencoder \u001b[39m=\u001b[39m autoencoder, epochs \u001b[39m=\u001b[39m epochs , n_folders \u001b[39m=\u001b[39m n_folders , preprocessing \u001b[39m=\u001b[39m preprocessing, ndim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39mverbose)\n",
            "\u001b[1;32m/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb Cella 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     autoencoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(main_dir,\u001b[39m'\u001b[39m\u001b[39mSaved_Models\u001b[39m\u001b[39m'\u001b[39m,AE_name))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#create the dataset\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m train, val, test, INPUT_DIM \u001b[39m=\u001b[39m  create_AS_dataset(folder_number\u001b[39m=\u001b[39mi,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                                                 preprocessing \u001b[39m=\u001b[39m preprocessing,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                                                 ndim \u001b[39m=\u001b[39m ndim,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                                                 main_dir \u001b[39m=\u001b[39m main_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                                                 )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#fit the autoencoder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/leonardo/Desktop/HDA/Human_Data_Analytics_Project_2023/AudioSet.ipynb#Y120sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m history \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mfit(train, validation_data\u001b[39m=\u001b[39m val, epochs\u001b[39m=\u001b[39mepochs, callbacks \u001b[39m=\u001b[39m callbacks, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: create_AS_dataset() got an unexpected keyword argument 'folder_number'"
          ]
        }
      ],
      "source": [
        "best_params = {\n",
        "    'n_layers':1,\n",
        "    'n_units':16,\n",
        "    'kernel_size':3,\n",
        "    'strides':3,\n",
        "    'max_pooling':3,\n",
        "    'regularizer':0.0001,\n",
        "    'padding':'valid',\n",
        "    'code_size':32,\n",
        "    'activation':'elu',\n",
        "    'drop_out':0.0,\n",
        "    'batch_norm':False,\n",
        "    'learning_rate':0.005,\n",
        "}\n",
        "\n",
        "\n",
        "# build an autoencoder with the best params\n",
        "autoencoder = build_autoencoder(**best_params)\n",
        "\n",
        "#autoencoder = tuner.get_best_models(num_models=1)[0] #to create the model with some already wuite good weights\n",
        "autoencoder.summary()\n",
        "verbose=0\n",
        "if verbose>0:\n",
        "    autoencoder.layers[1].summary()\n",
        "    autoencoder.layers[2].summary()\n",
        "\n",
        "epochs = 1 #50\n",
        "n_folders = 2 #528\n",
        "verbose = 0\n",
        "\n",
        "AS_training(AE_name = AE_name, autoencoder = autoencoder, epochs = epochs , n_folders = n_folders , preprocessing = preprocessing, ndim=3, verbose=verbose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
